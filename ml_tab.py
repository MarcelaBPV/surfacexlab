# ml_tab.py
# -*- coding: utf-8 -*-
"""
Aba 4 ‚Äî Otimiza√ß√£o ML (Machine Learning) para a SurfaceXLab

Fluxo:
- Upload de CSV com dados experimentais (j√° tratados ou agregados)
- Escolha da coluna-alvo (y)
- Escolha do tipo de problema (regress√£o ou classifica√ß√£o)
- Treino r√°pido de Random Forest
- Exibi√ß√£o de m√©tricas de desempenho
- Gr√°fico de import√¢ncias das vari√°veis

Observa√ß√£o:
- A aba tenta importar scikit-learn. Se n√£o estiver dispon√≠vel no ambiente,
  ela apenas mostra um aviso amig√°vel ao usu√°rio.
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------------------------------
# Tentativa de importar scikit-learn (opcional)
# ---------------------------------------------------
try:
    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import (
        r2_score,
        mean_absolute_error,
        mean_squared_error,
        accuracy_score,
    )

    SKLEARN_AVAILABLE = True
except Exception:
    SKLEARN_AVAILABLE = False


# ---------------------------------------------------
# Fun√ß√£o principal da aba
# ---------------------------------------------------
def render_ml_tab(supabase):
    st.header("4Ô∏è‚É£ Otimiza√ß√£o ML (Machine Learning)")

    st.markdown(
        """
Esta aba permite usar **modelos de Machine Learning** (Random Forest) para:

- Explorar rela√ß√µes entre par√¢metros de processo e propriedades de superf√≠cie  
- Testar modelos de regress√£o ou classifica√ß√£o com seus pr√≥prios dados (CSV)  

**Dica:** use aqui dados j√° resumidos (por exemplo: m√©dia de √¢ngulo de contato, RMS de rugosidade, √°rea de pico Raman, etc.).
"""
    )

    # Se scikit-learn n√£o est√° dispon√≠vel, avisa e encerra
    if not SKLEARN_AVAILABLE:
        st.warning(
            """
‚ö†Ô∏è `scikit-learn` n√£o est√° dispon√≠vel neste ambiente (Python do Streamlit Cloud ainda n√£o tem uma vers√£o compat√≠vel).

A aba de ML est√° **temporariamente desativada**.

Voc√™ ainda pode usar todas as outras abas (Raman, Tensiometria, Resistividade) normalmente.
"""
        )
        return

    st.markdown("---")

    # -----------------------------------------------
    # Upload de dados
    # -----------------------------------------------
    st.subheader("üìÇ Upload de dados experimentais (CSV)")

    file = st.file_uploader(
        "Envie um arquivo .csv com suas vari√°veis (colunas) e observa√ß√µes (linhas)",
        type=["csv"],
    )

    if file is None:
        st.info("Envie um arquivo CSV para come√ßar a configurar o modelo de ML.")
        return

    try:
        df = pd.read_csv(file)
    except Exception as e:
        st.error(f"Erro ao ler o CSV: {e}")
        return

    if df.empty:
        st.error("O arquivo CSV est√° vazio.")
        return

    st.markdown("#### Pr√©-visualiza√ß√£o dos dados")
    st.dataframe(df.head())

    # -----------------------------------------------
    # Escolha da coluna alvo (y) e tipo do problema
    # -----------------------------------------------
    st.markdown("---")
    st.subheader("üéØ Configura√ß√£o do modelo")

    target_col = st.selectbox(
        "Escolha a coluna alvo (vari√°vel que voc√™ quer prever):",
        df.columns,
    )

    feature_cols = [c for c in df.columns if c != target_col]
    if not feature_cols:
        st.error("O CSV precisa ter pelo menos 2 colunas (1 alvo + 1 feature).")
        return

    st.write("**Features (entradas do modelo):**", ", ".join(feature_cols))

    problem_type = st.radio(
        "Tipo de problema de ML:",
        ["Detec√ß√£o autom√°tica", "Regress√£o (valor cont√≠nuo)", "Classifica√ß√£o (r√≥tulos)"],
    )

    # -----------------------------------------------
    # Limpeza simples e prepara√ß√£o dos dados
    # -----------------------------------------------
    df_clean = df[feature_cols + [target_col]].dropna()
    if df_clean.empty:
        st.error("Ap√≥s remover valores ausentes (NaN), n√£o sobraram linhas suficientes.")
        return

    X_raw = df_clean[feature_cols]
    y_raw = df_clean[target_col]

    # one-hot encoding em colunas n√£o num√©ricas de X
    X = pd.get_dummies(X_raw, drop_first=True)

    # decis√£o autom√°tica sobre o tipo de problema (se escolhido)
    auto_type = None
    if problem_type == "Detec√ß√£o autom√°tica":
        # Heur√≠stica simples:
        # - se y for num√©rico e tiver muitos valores distintos -> regress√£o
        # - se y for texto ou tiver poucos valores distintos -> classifica√ß√£o
        if pd.api.types.is_numeric_dtype(y_raw):
            n_unique = y_raw.nunique()
            if n_unique <= max(10, len(y_raw) * 0.05):
                auto_type = "class"
            else:
                auto_type = "reg"
        else:
            auto_type = "class"
    elif problem_type.startswith("Regress√£o"):
        auto_type = "reg"
    else:
        auto_type = "class"

    # Para classifica√ß√£o: converter alvo em r√≥tulos num√©ricos
    y = y_raw.copy()
    class_labels = None
    if auto_type == "class":
        if not pd.api.types.is_numeric_dtype(y_raw):
            y_codes, uniques = pd.factorize(y_raw)
            y = pd.Series(y_codes, index=y_raw.index)
            class_labels = {i: lab for i, lab in enumerate(uniques)}
        else:
            class_labels = {int(v): str(v) for v in sorted(y.unique())}

    # -----------------------------------------------
    # Splitting treino/teste
    # -----------------------------------------------
    test_size = st.slider(
        "Propor√ß√£o para teste (test_size)",
        min_value=0.1,
        max_value=0.5,
        value=0.2,
        step=0.05,
    )

    random_state = st.number_input(
        "Random seed (para reprodutibilidade)",
        min_value=0,
        max_value=9999,
        value=42,
        step=1,
    )

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    st.write(f"N√∫mero de amostras de treino: {len(X_train)}")
    st.write(f"N√∫mero de amostras de teste: {len(X_test)}")

    # -----------------------------------------------
    # Hiperpar√¢metros simples
    # -----------------------------------------------
    st.markdown("---")
    st.subheader("‚öôÔ∏è Hiperpar√¢metros do modelo")

    col_m1, col_m2 = st.columns(2)

    with col_m1:
        n_estimators = st.slider(
            "N√∫mero de √°rvores (n_estimators)",
            min_value=50,
            max_value=500,
            value=200,
            step=50,
        )

    with col_m2:
        max_depth = st.slider(
            "Profundidade m√°xima das √°rvores (max_depth)",
            min_value=2,
            max_value=20,
            value=8,
            step=1,
        )

    # -----------------------------------------------
    # Treinar modelo
    # -----------------------------------------------
    if st.button("üöÄ Treinar modelo"):
        if auto_type == "reg":
            st.info("Treinando **RandomForestRegressor** (regress√£o)...")
            model = RandomForestRegressor(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=random_state,
                n_jobs=-1,
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            rmse = mean_squared_error(y_test, y_pred, squared=False)

            st.markdown("### üìä M√©tricas de Regress√£o")
            st.write(f"**R¬≤:** {r2:.4f}")
            st.write(f"**MAE (erro m√©dio absoluto):** {mae:.4f}")
            st.write(f"**RMSE:** {rmse:.4f}")

        else:
            st.info("Treinando **RandomForestClassifier** (classifica√ß√£o)...")
            model = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=random_state,
                n_jobs=-1,
            )
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            acc = accuracy_score(y_test, y_pred)

            st.markdown("### üìä M√©tricas de Classifica√ß√£o")
            st.write(f"**Acur√°cia:** {acc:.4f}")

            # Mapeia de volta os r√≥tulos, se tivermos dicion√°rio
            if class_labels is not None:
                st.markdown("**Mapeamento de classes:**")
                st.json(class_labels)

        # -------------------------------------------
        # Import√¢ncias de features
        # -------------------------------------------
        try:
            importances = model.feature_importances_
            feat_names = X.columns

            st.markdown("---")
            st.markdown("### üîç Import√¢ncia das vari√°veis (features)")

            imp_df = pd.DataFrame(
                {"feature": feat_names, "importance": importances}
            ).sort_values("importance", ascending=False)

            st.dataframe(imp_df)

            # Gr√°fico de barras das N principais
            top_n = st.slider(
                "N√∫mero de vari√°veis para mostrar no gr√°fico",
                min_value=3,
                max_value=min(20, len(imp_df)),
                value=min(10, len(imp_df)),
            )

            fig, ax = plt.subplots(figsize=(8, 4))
            top = imp_df.head(top_n).iloc[::-1]  # inverte para plotar de baixo pra cima
            ax.barh(top["feature"], top["importance"])
            ax.set_xlabel("Import√¢ncia relativa")
            ax.set_ylabel("Feature")
            ax.set_title("Import√¢ncia das vari√°veis no modelo")
            st.pyplot(fig)

        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel calcular/plotar import√¢ncias de features: {e}")
