# ml_tab.py
# -*- coding: utf-8 -*-

"""
SurfaceXLab ‚Äî Otimizador IA
PCA + Machine Learning supervisionado
"""

import streamlit as st
import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier


def render_ml_tab(supabase=None):

    st.header("ü§ñ Otimizador ‚Äî An√°lise Multivariada e IA")

    st.markdown("""
    Esta aba integra **An√°lise de Componentes Principais (PCA)** e
    **modelos de aprendizado supervisionado**, utilizando fingerprints
    espectrais extra√≠dos previamente.
    """)

    # -----------------------------------------------------
    # 1Ô∏è‚É£ Carregar fingerprints (exemplo: tabela fingerprints)
    # -----------------------------------------------------
    st.subheader("Base de dados")

    try:
        res = supabase.table("raman_fingerprints").select("*").execute()
        data = res.data if res.data else []
    except Exception:
        data = []

    if not data:
        st.warning("Nenhum fingerprint dispon√≠vel no banco.")
        return

    df = pd.DataFrame(data)

    label_col = st.selectbox(
        "Vari√°vel alvo (classe)",
        options=[c for c in df.columns if c not in ("id", "created_at")]
    )

    X = df.drop(columns=[label_col, "id", "created_at"], errors="ignore")
    y = df[label_col]

    # -----------------------------------------------------
    # 2Ô∏è‚É£ PCA
    # -----------------------------------------------------
    st.subheader("An√°lise de Componentes Principais (PCA)")

    n_components = st.slider(
        "N√∫mero de componentes principais",
        min_value=2,
        max_value=min(6, X.shape[1]),
        value=2
    )

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    pca = PCA(n_components=n_components)
    scores = pca.fit_transform(X_scaled)

    scores_df = pd.DataFrame(
        scores,
        columns=[f"PC{i+1}" for i in range(n_components)]
    )

    st.write("üìä Vari√¢ncia explicada:")
    st.write(pca.explained_variance_ratio_)

    st.dataframe(scores_df)

    # -----------------------------------------------------
    # 3Ô∏è‚É£ Loadings
    # -----------------------------------------------------
    st.subheader("Loadings (contribui√ß√£o das vari√°veis)")

    loadings_df = pd.DataFrame(
        pca.components_.T,
        index=X.columns,
        columns=[f"PC{i+1}" for i in range(n_components)]
    )

    st.dataframe(loadings_df)

    # -----------------------------------------------------
    # 4Ô∏è‚É£ ML supervisionado
    # -----------------------------------------------------
    st.subheader("Aprendizado supervisionado")

    X_train, X_test, y_train, y_test = train_test_split(
        scores, y, test_size=0.25, random_state=42
    )

    model = RandomForestClassifier(
        n_estimators=200,
        random_state=42
    )

    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)

    st.metric("Acur√°cia", f"{acc:.2f}")

    st.write("üìâ Matriz de confus√£o:")
    st.dataframe(
        pd.DataFrame(
            confusion_matrix(y_test, y_pred),
            index=["Real 0", "Real 1"],
            columns=["Pred 0", "Pred 1"]
        )
    )
